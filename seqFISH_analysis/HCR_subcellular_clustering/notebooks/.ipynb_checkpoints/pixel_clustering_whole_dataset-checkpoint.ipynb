{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8819b664-823c-4ae2-9582-6b629222ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from itertools import cycle\n",
    "from pathlib import Path, PureWindowsPath\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tifffile\n",
    "import skimage\n",
    "import pandas as pd\n",
    "from skimage.filters import threshold_li\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from skimage import exposure, io\n",
    "from joblib import Parallel, delayed\n",
    "import napari\n",
    "import anndata as ad\n",
    "import scanorama\n",
    "import scanpy as sc\n",
    "from fbpca import pca\n",
    "from geosketch import gs\n",
    "from matplotlib.pyplot import rc_context\n",
    "import h5py \n",
    "\n",
    "sc.settings.verbosity = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fcb19b79-f857-4821-9498-a33f5ffa4ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6aaaf3ab-2f1f-4650-a1fd-f06c78fa91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'Y:\\coskun-lab\\Zhou\\4_HCR\\2D_analyses_pipelines\\subcellular_clustering\\v2\\bm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4fa5040e-ca3d-4f33-94d7-af8825ecd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd().parent / 'data' / 'meta' / 'pixels_clusters.h5ad'\n",
    "adata = ad.read_h5ad(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5115f48-7919-4f91-9462-4cda614b4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the subset is the same \n",
    "sketch_index= np.load(\n",
    "    Path.cwd().parent / 'data' / 'clustering'/ 'index.npy'\n",
    ")\n",
    "\n",
    "adata_subset = adata[sketch_index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4f8f7-612f-4e9c-a4d3-d46018b54e91",
   "metadata": {},
   "source": [
    "# Propagate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4522ca15-6b1e-4c61-a4db-b351e485a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynndescent\n",
    "import scanorama\n",
    "from typing import Optional\n",
    "\n",
    "def get_img_from_data(x: np.ndarray, y: np.ndarray, data: np.ndarray, pad: int = 0) -> np.ndarray:\n",
    "    # X is row and Y col\n",
    "    x_coord = x - x.min() + pad\n",
    "    y_coord = y - y.min() + pad\n",
    "    # create image\n",
    "    img = np.zeros(\n",
    "        (x_coord.max() + 1 + pad, y_coord.max() + 1 + pad, data.shape[-1]),\n",
    "        dtype=data.dtype,\n",
    "    )\n",
    "    img[x_coord, y_coord] = data\n",
    "    return img\n",
    "\n",
    "def hex2rgb(h):\n",
    "    \"\"\"Convert hex color string to rgb tuple.\"\"\"\n",
    "    h = h.lstrip(\"#\")\n",
    "    return [int(h[i : i + 2], 16) for i in (0, 2, 4)]\n",
    "\n",
    "def annotate_img(\n",
    "    img: np.ndarray,\n",
    "    annotation: Optional[pd.DataFrame] = None,\n",
    "    from_col: str = \"clustering\",\n",
    "    to_col: Optional[str] = None,\n",
    "    color: bool = False,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Annotate cluster image.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img\n",
    "        Image to annotate.\n",
    "    annotation\n",
    "        :attr:`Cluster.cluster_annotation` containing mapping of classes to cluster names and colors.\n",
    "    from_col\n",
    "        Annotation column containing current values in image.\n",
    "    to_col\n",
    "        Annotation column containing desired mapping. If None, use ``from_col``.\n",
    "    color\n",
    "        If True, use annotation column ``to_col+\"_colors\"`` to get colormap and color image.\n",
    "    Returns\n",
    "    -------\n",
    "    Annotated image.\n",
    "    \"\"\"\n",
    "    if to_col is None:\n",
    "        to_col = from_col\n",
    "    if color:\n",
    "        to_col = to_col + \"_colors\"\n",
    "        res = np.zeros(img.shape + (3,), dtype=np.uint8)\n",
    "    else:\n",
    "        if from_col == to_col:\n",
    "            # no need to change anything\n",
    "            return img\n",
    "        assert annotation is not None\n",
    "        res = np.zeros_like(img, dtype=annotation[to_col].dtype)\n",
    "    assert annotation is not None\n",
    "    for _, row in annotation.iterrows():\n",
    "        to_value = row[to_col]\n",
    "        if color:\n",
    "            to_value = hex2rgb(to_value)\n",
    "        res[img == row[from_col]] = to_value\n",
    "    return res.squeeze() if color else res\n",
    "\n",
    "def get_max_frequency_label(labels, neighs, n):\n",
    "    df = pd.get_dummies(labels)\n",
    "    dummies = df.values\n",
    "    dummies_labels = np.array(df.columns.tolist())\n",
    "    window = dummies[neighs]\n",
    "    window = window.reshape(-1, n_neighbor, dummies.shape[1])\n",
    "    window = window.sum(axis=1) / n_neighbor\n",
    "    \n",
    "    assert len(window) == len(neighs)\n",
    "    return dummies_labels[np.argmax(window, axis=1)]\n",
    "\n",
    "def missing_elements(X, L):\n",
    "    start, end = 0, len(X)-1\n",
    "    return sorted(set(range(start, end + 1)).difference(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c9d01bb-e96d-4b46-adf1-26d80477648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbor = 30\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 100000\n",
    "\n",
    "# Get subset labels\n",
    "labels = adata_subset.obs.cluster\n",
    "\n",
    "# Get already process data\n",
    "adatas  = []\n",
    "for batch in adata_subset.obs[\"FOV\"].unique():\n",
    "    adata_temp = adata_subset[\n",
    "        adata_subset.obs[\"FOV\"] == batch\n",
    "    ]\n",
    "    adatas.append(adata_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "15dacabd-fd32-45b8-a6a6-38d580b685cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.DataFrame()\n",
    "annotations['cluster'] = adata.obs.cluster.cat.categories\n",
    "annotations['cluster_colors'] = adata.uns['cluster_colors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa82049f-5f5f-4d88-a9a3-8c450bf41f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['gapdh', 'actb', 'il8', 'il6', 'ccl11', 'col1a1', 'nanog', 'sox9', 'eef2', 'spp1', 'runx1', 'pdl1', 'ConA', 'PhA', 'WGA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2971d45-53e6-4666-a289-03c8adfb4ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (dirpath, dirnames, filenames) in os.walk(Path.cwd().parent / 'data' / 'h5'):\n",
    "    for name in tqdm(sorted(filenames)):\n",
    "        # Read h5 file for pixel intensity\n",
    "        path = os.path.join(dirpath, name)\n",
    "        f = h5py.File(path)\n",
    "        \n",
    "        img_path = Path.cwd().parent / 'figures' / 'pixels' / f'{name[:-3]}.png'\n",
    "        if os.path.exists(img_path):\n",
    "            print(img_path)\n",
    "            continue\n",
    "        \n",
    "        # Get info\n",
    "        cell_type = '_'.join(name.split('_')[:-1])\n",
    "        fov = name.split('_')[-1][:-3]\n",
    "        \n",
    "        # Extract df and convert to anndata format\n",
    "        df = pd.DataFrame(f['df']['table'][:])\n",
    "        adata_fov = sc.AnnData(df.loc[:, markers].values)\n",
    "        adata_fov.var_names = adata_subset.var_names\n",
    "        sc.pp.scale(adata_fov, max_value=4)\n",
    "        \n",
    "        # Get already process adata \n",
    "        adatas  = []\n",
    "        for batch in adata_subset.obs[\"FOV\"].unique():\n",
    "            adata_temp = adata_subset[\n",
    "                adata_subset.obs[\"FOV\"] == batch\n",
    "            ]\n",
    "            adatas.append(adata_temp)\n",
    "        adatas.append(adata_fov)\n",
    "        scanorama.integrate_scanpy(adatas, sketch=True, dimred=10) \n",
    "        \n",
    "        # Get scanorama correction\n",
    "        adata_subset_cor = ad.concat(adatas[:-1])\n",
    "        \n",
    "        # Get NNDescent index for fast projection\n",
    "        X_clustered = adata_subset_cor.obsm['X_scanorama']\n",
    "        index = pynndescent.NNDescent(X_clustered)\n",
    "        \n",
    "        # project clusters\n",
    "        clustering = []\n",
    "        samples = adatas[-1].obsm['X_scanorama']\n",
    "        for i in np.arange(0, samples.shape[0], batch_size):\n",
    "            print(f\"processing chunk {i}\")\n",
    "            cur_samples = samples[i : i + batch_size]\n",
    "            neighs = index.query(cur_samples.astype(np.float32), k=n_neighbor)[0]\n",
    "            clustering.append(\n",
    "                get_max_frequency_label(labels, neighs, n_neighbor)\n",
    "            )\n",
    "        full_labels = np.concatenate(clustering)\n",
    "        \n",
    "        df_subset = df[['Cell Type', 'Id']]\n",
    "        df_subset['Cluster'] = full_labels\n",
    "        df_subset.to_csv(Path.cwd().parent / 'data' / 'pixels' / f'{name[:-3]}.csv', index=False)\n",
    "        \n",
    "        # Create images\n",
    "        \n",
    "        x = np.array(df.X.values)\n",
    "        y = np.array(df.Y.values)\n",
    "        values = full_labels\n",
    "\n",
    "        if len(values.shape) == 1:\n",
    "                values = values[:, np.newaxis]\n",
    "        img_cluster = get_img_from_data(x, y, values)\n",
    "        img_cluster_annotated = annotate_img(img_cluster, annotations, from_col='cluster', color=True)\n",
    "        skimage.io.imsave(img_path, img_cluster_annotated)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc1db8-7ca4-463b-9507-db73343ae00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-thomas-env] *",
   "language": "python",
   "name": "conda-env-.conda-thomas-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
